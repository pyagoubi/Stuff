{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMd5sY0Nc7iidp8JusPM/3m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pyagoubi/Stuff/blob/main/Untitled15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q91fSnZuQgn2",
        "outputId": "e4cdc160-2d63-43db-b34a-fc5f75937ed4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install backtesting\n",
        "\n",
        "import backtesting as bt\n",
        "from backtesting import Backtest, Strategy"
      ],
      "metadata": {
        "id": "8R6JWeuGRI4B"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import datetime as dt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "# set cpu or gpu enabled device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu').type"
      ],
      "metadata": {
        "id": "DVF3UKTFRQlz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create LSTM model for 1 day forecasting"
      ],
      "metadata": {
        "id": "PfjAAAwER0EN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class cfg_LSTM1d:  \n",
        "  split_fraction = 0.85\n",
        "  time_steps = 5 # number of predictor timesteps\n",
        "  horizon = 1 # number of timesteps to be predicted\n",
        "  sequence_length = time_steps + horizon # determine sequence length\n",
        "  learning_rate=0.01\n",
        "  num_epochs=2000\n",
        "  path = '/content/drive/MyDrive/stock predict/technical/1D_technical.csv'\n",
        "  features = ['close']\n",
        "  target = 'close'\n",
        "  input_size = len(features)\n",
        "\n",
        "\n",
        "def load_1ddata(path = cfg_LSTM1d.path, features = cfg_LSTM1d.features):\n",
        "  data_1draw = pd.read_csv(path)\n",
        "  data_1draw.columns = data_1draw.columns.str.replace(' ', '')\n",
        "  data_1draw['time'] = pd.to_datetime(data_1draw['time'])\n",
        "  data_1draw['time'] = data_1draw['time'].dt.date\n",
        "  data_1draw.set_index('time', inplace=True)\n",
        "  df_1d = data_1draw[features].copy()\n",
        "  return df_1d, data_1draw\n",
        "\n",
        "\n",
        "def trainvalidsplit(df_1d = df_1d, split_fraction = cfg_LSTM1d.split_fraction):\n",
        "  split_row = int(df_1d.shape[0] * split_fraction)\n",
        "  train_1d = df_1d.iloc[:split_row].copy()\n",
        "  valid_1d = df_1d.iloc[split_row:].copy()\n",
        "  return train_1d, valid_1d\n",
        "\n",
        "def scale1d(train_1d, valid_1d,f_scaler1d, \n",
        "            t_scaler1d, input_size = cfg_LSTM1d.input_size, target = cfg_LSTM1d.target ):\n",
        "  \n",
        "  train_1d_scaled = train_1d.copy()\n",
        "  valid_1d_scaled = valid_1d.copy()  \n",
        "  \n",
        "  if input_size == 2:\n",
        "    train_1d_scaled.loc[:, train_1d.columns != target] = f_scaler1d.fit_transform(train_1d_scaled.loc[:, train_1d_scaled.columns != target].values.reshape(-1,1))\n",
        "    valid_1d_scaled.loc[:, valid_1d.columns != target] = f_scaler1d.transform(valid_1d.loc[:, valid_1d_scaled.columns != target].values.reshape(-1,1))\n",
        "  elif input_size >2:\n",
        "    train_1d_scaled.loc[:, train_1d.columns != target] = f_scaler1d.fit_transform(train_1d_scaled.loc[:, train_1d_scaled.columns != target])\n",
        "    valid_1d_scaled.loc[:, valid_1d.columns != target] = f_scaler1d.fit_transform(valid_1d_scaled.loc[:, valid_1d_scaled.columns != target])\n",
        "\n",
        "  train_1d_scaled[target] = t_scaler1d.fit_transform(train_1d[target].values.reshape(-1,1))\n",
        "  valid_1d_scaled[target] = t_scaler1d.transform(valid_1d[target].values.reshape(-1,1))\n",
        "  return train_1d_scaled, valid_1d_scaled\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bGnWvgmdR2I4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f_scaler1d = MinMaxScaler(feature_range=(-1, 1))\n",
        "t_scaler1d = MinMaxScaler(feature_range=(-1, 1))\n",
        "\n",
        "df_1d, data_1draw = load_1ddata()\n",
        "train_1d, valid_1d = trainvalidsplit(df_1d)\n",
        "train_1d_scaled, valid_1d_scale = scale1d(train_1d, valid_1d,f_scaler1d, t_scaler1d)\n"
      ],
      "metadata": {
        "id": "dA0TrTx2VbaN"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}