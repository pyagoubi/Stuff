{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "authorship_tag": "ABX9TyMn5JzKQ+34lvzkaKxQpBfI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pyagoubi/Stuff/blob/main/stockprediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fLfxPOfE4DL",
        "outputId": "45633a8a-524b-44b0-c7f1-37b14bf7a993"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install bt"
      ],
      "metadata": {
        "id": "SkB6VukkwtQ5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils import data\n",
        "from torch.utils.data import dataloader\n",
        "import bt as bt\n",
        "import os, sys, itertools, urllib, io\n",
        "import datetime as dt\n",
        "import pandas as pd\n",
        "import pandas_datareader as dr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "oSKi_kqqwtKb"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tech_daily_raw = pd.read_csv('/content/drive/MyDrive/stock predict/technical/1D_technical.csv')\n",
        "features = ['open', 'high', 'low', 'close', 'rsi', 'adx', 'cci', 'ema', 'stoch', 'trend_macd', 'momentum_stoch', 'volatility_atr']\n",
        "tech_daily = tech_daily_raw[features]\n",
        "\n",
        "# init deterministic seed\n",
        "seed_value = 1234\n",
        "np.random.seed(seed_value) # set numpy seed\n",
        "torch.manual_seed(seed_value); # set pytorch seed CPU\n",
        "\n",
        "# set cpu or gpu enabled device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu').type\n",
        "\n",
        "# init deterministic GPU seed\n",
        "torch.cuda.manual_seed(seed_value)\n",
        "\n",
        "# log type of device enabled\n",
        "now = dt.datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
        "print('[LOG {}] notebook with \\'{}\\' computation enabled'.format(str(now), str(device)))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "A2x5ZKh-yCSd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3d2282d-837f-447f-b6bd-32dca070ba94"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LOG 20230516-13:09:35] notebook with 'cuda' computation enabled\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tech_daily = tech_daily.copy()\n",
        "tech_daily['return'] = np.log(tech_daily['close']) - np.log(tech_daily['close'].shift(1))"
      ],
      "metadata": {
        "id": "DaVKZxUTWhzG"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = features + ['return']"
      ],
      "metadata": {
        "id": "Txfyq7B1WhsD"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "tech_daily_scaled = pd.DataFrame(scaler.fit_transform(tech_daily), columns = features)"
      ],
      "metadata": {
        "id": "nsxKS_orrnTP"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_fraction = 0.9\n",
        "split_row = int(tech_daily.shape[0] * split_fraction)\n",
        "train_stock_data_return = tech_daily.iloc[:split_row]\n",
        "valid_stock_data_return = tech_daily.iloc[split_row:]"
      ],
      "metadata": {
        "id": "uFDj_0uKWhmK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_steps = 4 # number of predictor timesteps\n",
        "horizon = 1 # number of timesteps to be predicted\n",
        "sequence_length = time_steps + horizon # determine sequence length"
      ],
      "metadata": {
        "id": "3zH0TwSZWhjD"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(df, sequence_length):\n",
        "    # Normalize the data\n",
        "    #normalized_data = (df - df.mean()) / df.std()\n",
        "\n",
        "    # Convert the DataFrame to a numpy array\n",
        "    #data_array = normalized_data.values\n",
        "\n",
        "    data_array = df.values\n",
        "\n",
        "    # Split the data into sequences\n",
        "    sequences = []\n",
        "    for i in range(len(data_array) - sequence_length):\n",
        "        sequence = data_array[i : i + sequence_length + 1]\n",
        "        sequences.append(sequence)\n",
        "\n",
        "    # Convert sequences to PyTorch tensors\n",
        "    tensor_sequences = [torch.Tensor(seq) for seq in sequences]\n",
        "\n",
        "    # Stack the tensor sequences\n",
        "    stacked_sequences = torch.stack(tensor_sequences)\n",
        "\n",
        "    return stacked_sequences\n",
        "\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) - 1\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.Tensor(self.data[idx, :-1])  # Input features (all columns except the last one)\n",
        "        y = torch.Tensor([self.data[idx + 1, -1]])  # Target variable ('return' column for the next time step)\n",
        "        return x, y"
      ],
      "metadata": {
        "id": "OOzpxsJGWhdL"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_stock_data_return = preprocess_data(df, sequence_length) \n",
        "valid_stock_data_return"
      ],
      "metadata": {
        "id": "525pgRC716_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EPnVhTAS16y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = MyDataset(preprocessed_data)"
      ],
      "metadata": {
        "id": "FXPn7anV16ml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "il3PZrLAWg8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oeh8Xx5uWg5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CaPkLqYOWg1i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}